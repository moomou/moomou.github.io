<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on moomou</title>
    <link>/notes/</link>
    <description>Recent content in Notes on moomou</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>since 2017</copyright>
    <lastBuildDate>Fri, 01 Sep 2017 23:01:25 -0700</lastBuildDate>
    <atom:link href="/notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ML paper notes</title>
      <link>/notes/ml_notes/</link>
      <pubDate>Fri, 01 Sep 2017 23:01:25 -0700</pubDate>
      <guid>/notes/ml_notes/</guid>
      <description>&lt;h3 id=&#34;2017-09&#34;&gt;&#xA;  2017-09&#xA;  &lt;a href=&#34;#2017-09&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h2 id=&#34;learning-fine-grained-image-similarity-with-deep-ranking&#34;&gt;&#xA;  LEARNING FINE-GRAINED IMAGE SIMILARITY WITH DEEP RANKING&#xA;  &lt;a href=&#34;#learning-fine-grained-image-similarity-with-deep-ranking&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;describes efficient sampling technique based on reservoir sampling for building triplets; requires an relevance function&lt;/li&gt;&#xA;&lt;li&gt;multi scale CNN&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;deep-metric-learning-using-triplet-network&#34;&gt;&#xA;  DEEP METRIC LEARNING USING TRIPLET NETWORK&#xA;  &lt;a href=&#34;#deep-metric-learning-using-triplet-network&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;learns a semantic embedding; results show better discrimination vs siamese network (contrastive loss function)&lt;/li&gt;&#xA;&lt;li&gt;MSE softmax shows improved performance rather than simple binary softmax (see paper for def)&lt;/li&gt;&#xA;&lt;li&gt;feed a triplet of x, x1, x2 where x1 is same class as x and x2 is different&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;distilling-the-knowledge-in-a-neural-network&#34;&gt;&#xA;  DISTILLING THE KNOWLEDGE IN A NEURAL NETWORK&#xA;  &lt;a href=&#34;#distilling-the-knowledge-in-a-neural-network&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;explores compression technique of ensemble model into a single model&lt;/li&gt;&#xA;&lt;li&gt;Distillation&#xA;&lt;ul&gt;&#xA;&lt;li&gt;softmax qi = exp(zi/T)/Sigma(j)(exp(zj/T) where z are logits and T is temperature&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;T is usually 1&lt;/li&gt;&#xA;&lt;li&gt;increasing T creates softer probability distribution&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;knowledge is tranferred via training smaller/compressed model by targeting over softer target (ie temperature T &amp;gt; 1) from more cumbersome model&lt;/li&gt;&#xA;&lt;li&gt;small model trained with higher T as well but in prediction mode uses T = 1&lt;/li&gt;&#xA;&lt;li&gt;tranfer training can be improved by using datasets with true label&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;demonstrate distillation with minist dataset - tranfer works well even when smaller model trained by omitting certain numbers&lt;/li&gt;&#xA;&lt;li&gt;discusses using soft distribution target technique for training specialists on very large datasets&lt;/li&gt;&#xA;&lt;li&gt;Google internal JFT data of 100M images&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;questions&#34;&gt;&#xA;  Questions&#xA;  &lt;a href=&#34;#questions&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;teacher - student model, relation to curriculum learning?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tools</title>
      <link>/notes/tools/</link>
      <pubDate>Fri, 01 Sep 2017 23:01:25 -0700</pubDate>
      <guid>/notes/tools/</guid>
      <description>&lt;h2 id=&#34;fzf&#34;&gt;&#xA;  Fzf&#xA;  &lt;a href=&#34;#fzf&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Amazing command line tool to fuzzy search for files. Cannot live without this. Also integrates with vim.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/junegunn/fzf&#34;&gt;https://github.com/junegunn/fzf&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;jq&#34;&gt;&#xA;  Jq&#xA;  &lt;a href=&#34;#jq&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Swiss army knife for working with JSON on the command line&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/stedolan/jq&#34;&gt;https://github.com/stedolan/jq&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;pup&#34;&gt;&#xA;  Pup&#xA;  &lt;a href=&#34;#pup&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Like Jq, but for HTML&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ericchiang/pup&#34;&gt;https://github.com/ericchiang/pup&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;silversearcher&#34;&gt;&#xA;  Silversearcher&#xA;  &lt;a href=&#34;#silversearcher&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Like grep, but better&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ggreer/the_silver_searcher&#34;&gt;https://github.com/ggreer/the_silver_searcher&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
